### 1.線性代數中的『線性』指的是什麼？為何要稱為『代數』  
### 答:  
滿足以下兩條件：  
對任意向量 u, v 和任意實數（或複數） a, b：T(au+bv)=aT(u)+bT(v)
1. 可加性：T(u+v)=T(u)+T(v)
2. 齊次性：T(αu)=αT(u)
代數指研究一組帶有運算規則的元素的結構
### 2.數學中的『空間』是什麼？為何『向量空間』被稱為空間  
### 答:  
現代數學中，「空間」= 一個集合 + 結構  
向量空間:滿足「加減、伸縮」的幾何直覺
### 3.矩陣和向量之間有何關係？矩陣代表的意義是什麼？ 
### 答:    
矩陣 = 線性變換的座標表示
向量 → 一個空間的元素
矩陣 → 把向量變成另一個向量的「線性規則」  
### 4.如何用矩陣代表 2D / 3D 幾何學中的『平移，縮放，旋轉』操作？  
### 答:
2D 平移矩陣:  
1 0 dx  
0 1 dy  
0 0 1  
2D 縮放:  
sx 0 0  
0 sy 0  
0 0  1  
2D 旋轉矩陣:  
cosθ -sinθ 0  
sinθ cosθ  0  
0       0  1   
### 5.行列式的意義是什麼？如何用遞迴公式計算矩陣的行列式？行列式和體積有什麼關係？ 
### 答:
行列式 = 空間被矩陣拉伸的「體積倍數」  
1. A=PDP−1  
2. A=LU，det(A)=det(L)det(U)
### 6.特徵值和特徵向量的意義是什麼？特徵值分解有何用途？
### 答:
Av=λv  
矩陣 A 的作用在向量 v 上，不會改變方向、只會「伸縮」 λ 倍
### 7.QR 分解是什麼？
### 答:
A=QR:Q：正交矩陣（旋轉）、R：上三角矩陣（縮放 + 斜率）  
### 8.如何反覆用 QR 分解，完成特徵值分解？
### 答:
Ak+1​=Rk​Q，會使 A 趨近於上三角矩陣，其對角線即特徵值。
### 9.SVD 分解是什麼？和特徵值分解有何關係？
### 答:
A=UΣVT  
V：在輸入空間中找出最佳方向  
Σ：沿這些方向的伸縮量（奇異值）  
U：伸縮後的方向  
### 10.主成分分析是什麼？和 SVD 分解有何關係？
### 答:
PCA = covariance matrix 的 SVD
